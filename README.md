# Python_Modelos_Predicao_Estatistica
An√°lise comparativa de algoritmos essenciais de Machine Learning para Regress√£o e Classifica√ß√£o usando Python (Scikit-learn, Pandas) e Jupyter Notebooks.

### ‚öñÔ∏è An√°lise Comparativa dos Modelos de Regress√£o Base (Python/Scikit-learn)

#### Regress√£o Linear M√∫ltipla (`mpg ~ wt + hp`)

O treinamento em Python (utilizando `statsmodels` para an√°lise estat√≠stica detalhada) replicou com sucesso os resultados obtidos em R, confirmando a validade do modelo:

| M√©trica | Resultado |
| :--- | :--- |
| **R-quadrado Ajustado** | $\mathbf{0.8148}$ |
| **RSE (RMSE)** | $\mathbf{2.593}$ |
| **Coeficiente do Peso (`wt`)** | $-3.8778$ |
| **P-valor do `hp`** | $0.001$ |

**Previs√£o de Exemplo:**

| Par√¢metros de Entrada | Previs√£o de MPG |
| :--- | :--- |
| $\text{Peso} = 3.000$ lbs, $\text{HP} = 150$ | $\mathbf{20.83}$ |

**Conclus√£o:** O modelo √© estatisticamente robusto, com $81.48\%$ da vari√¢ncia de MPG explicada, e o efeito da multicolinearidade entre Peso e Horsepower √© corretamente contabilizado.

### üìê An√°lise de Forma Funcional: Linear vs. Polinomial

Esta se√ß√£o compara o modelo Linear M√∫ltiplo (que foi o melhor ajuste linear) com os modelos Polinomiais de 2¬∫ e 3¬∫ Graus (`mpg` ~ $\text{hp} + \text{hp}^2$, etc.), a fim de determinar a melhor forma de modelar a rela√ß√£o.

#### Comparativo Consolidado de Desempenho (mtcars)

| Modelo | F√≥rmula | R-quadrado Ajustado | RSE (RMSE) | Termos Polinomiais Significativos ($\text{P} < 0.05$) |
| :--- | :--- | :--- | :--- | :--- |
| **Linear M√∫ltiplo** | $\text{mpg} \sim \text{wt} + \text{hp}$ | $\mathbf{0.8148}$ | $\mathbf{2.593}$ | N/A |
| **Polinomial 2¬∫ Grau** | $\text{mpg} \sim \text{hp} + \text{hp}^2$ | $0.7393$ | $3.077$ | $\text{hp}^2$ (**Sim**) |
| **Polinomial 3¬∫ Grau** | $\text{mpg} \sim \text{hp} + \text{hp}^2 + \text{hp}^3$ | $0.7349$ | $3.103$ | Nenhum ($\text{hp}^2$ e $\text{hp}^3$ n√£o significativos) |

#### Conclus√£o sobre a Modelagem

1.  **Signific√¢ncia da Curvatura:** O termo quadr√°tico ($\text{hp}^2$) foi estatisticamente significativo no modelo de 2¬∫ grau, provando que a rela√ß√£o entre $\text{HP}$ e $\text{MPG}$ **n√£o √© estritamente linear**.
2.  **Modelo Preditivo Vencedor:** Apesar da comprova√ß√£o da curvatura, o modelo **Linear M√∫ltiplo** ($\text{mpg} \sim \text{wt} + \text{hp}$) se mostrou o **melhor modelo preditivo** em termos de ajuste ($\mathbf{R^2_{adj}=0.8148}$) e precis√£o ($\mathbf{RSE=2.593}$).
3.  **Estrat√©gia Ideal:** Para o *dataset* `mtcars`, a **combina√ß√£o de *features* independentes** ($\text{wt}$ e $\text{hp}$) foi significativamente mais eficaz para reduzir o erro de previs√£o do que tentar modelar a forma n√£o-linear de um √∫nico *feature* ($\text{hp}$). O modelo Polinomial de 3¬∫ Grau, al√©m de n√£o ser significativo, teve o pior desempenho.

---
### üìà Regulariza√ß√£o de Modelos (Ridge, Lasso e Elastic Net)

Os modelos de regulariza√ß√£o foram aplicados ao *dataset* California Housing para otimizar a performance, prevenir o *overfitting* e realizar a sele√ß√£o de *features*.

#### Comparativo de Desempenho (California Housing)

| Modelo | Penalidade | Melhor Alpha ($\lambda$) | L1 Ratio ($\alpha$) | RMSE (Teste) | R¬≤ (Teste) | Sele√ß√£o de Features |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Ridge (L2)** | $L2$ | $4.3288$ | $0.0000$ | $\mathbf{0.5305}$ | $0.5959$ | Encolhe (n√£o zera) |
| **Lasso (L1)** | $L1$ | $0.0027$ | $1.0000$ | $0.7270$ | $0.5973$ | $\text{Population}$ zerada |
| **Elastic Net** | $L1 + L2$ | $0.0027$ | $\mathbf{1.0000}$ | $0.7270$ | $0.5973$ | $\text{Population}$ zerada |

#### Conclus√£o Final da Regulariza√ß√£o

1.  **Modelo Vencedor:** A **Regress√£o Ridge (L2)** se mostrou o **modelo preditivo superior**, com o menor erro (RMSE de $\mathbf{0.5305}$). Isso sugere que, para este *dataset*, √© melhor manter todas as *features*, apenas encolhendo seus pesos.
2.  **Lasso e Elastic Net:** Ambos otimizaram para o mesmo ponto (Elastic Net otimizou para ser Lasso puro, $\mathbf{L1\_Ratio=1.0}$), zerando o peso da vari√°vel $\text{Population}$. No entanto, essa remo√ß√£o resultou em uma perda significativa na precis√£o ($\text{RMSE}$ $\mathbf{\approx 37\%}$ maior).

O modelo **Ridge** ser√° o modelo escolhido para a fase de *deployment* e produ√ß√£o, devido √† sua precis√£o superior.

## üìä Diferen√ßa de Resultados Devido √† Troca de Datasets

Os resultados da regulariza√ß√£o (Ridge, Lasso e Elastic Net) obtidos em **Python (California Housing)** e em **R (Boston Housing)** apresentaram uma diferen√ßa significativa na escolha do modelo de penalidade ideal.

Essa diverg√™ncia √© causada pela **diferen√ßa fundamental** entre os dois *datasets* utilizados: o **tamanho amostral** e o **contexto dos dados**.

---

### 1. Comportamento Ideal da Penalidade por Dataset

| Caracter√≠stica | Boston Housing (R) | California Housing (Python) |
| :--- | :--- | :--- |
| **Tamanho Amostral ($N$)** | Pequeno ($N=506$) | Grande ($\mathbf{N=20.640}$) |
| **Ideal de Regulariza√ß√£o** | **Elastic Net (L2-Dominante)** | **Ridge (L2)** |
| **Melhor L1 Ratio ($\alpha$)** | $\mathbf{0.1111}$ ($\approx 90\%$ L2) | $\mathbf{0.0000}$ (Ridge Puro) |
| **Motivo** | Prioriza a **estabilidade (L2)** em *datasets* pequenos, pois a exclus√£o de *features* pelo Lasso √© arriscada. | Prioriza a **estabilidade (L2)** para o menor erro. O Lasso teve perda preditiva significativa ao remover o *feature* `Population`. |
| **Vencedor Final** | Elastic Net (RMSE: 5.179) | **Ridge** (RMSE: 0.5305) |

---

### 2. Implica√ß√µes da Diverg√™ncia

O Elastic Net √© projetado para encontrar a melhor **mistura** ($\alpha$) de penalidades L1 e L2.

* No **Boston Housing (R)**, o Elastic Net otimizou para um modelo **majoritariamente Ridge** ($\alpha \approx 0.11$), confirmando que a penalidade L2 (estabilidade) √© mais importante.
No **California Housing (Python)**, o Lasso e o Elastic Net (que otimizou para ser Lasso Puro: $\text{L1}_{\text{Ratio}}=1.0$) tiveram um desempenho **muito inferior** ao Ridge (L2).

**Conclus√£o Consolidada:**

Em ambos os *datasets*, a abordagem vencedora foi **priorizar a penalidade Ridge (L2)**, que **encolhe** os coeficientes sem zer√°-los.

* O **Boston Housing** exigiu o Elastic Net para encontrar essa **domin√¢ncia L2**.
* O **California Housing** demonstrou que o **Ridge Puro** √© o mais robusto e preditivo, confirmando que a estabilidade √© a chave para o melhor desempenho em ambos os contextos.

---

### üöÄ Modelos N√£o Linear e M√©todos de Ensemble

Os modelos de Regress√£o N√£o Linear (KNN) e os M√©todos de Ensemble (Random Forest e XGBoost) foram aplicados ao *dataset* California Housing para capturar rela√ß√µes mais complexas e atingir maior precis√£o. J√° os modelos de Classifica√ß√£o N√£o Linear (KNN) e os modelos de Ensemble (Random Forest e XGBoost) foram aplicado ao *dataset* Pima Indian Diabetes.

## ‚öôÔ∏è Modelos N√£o Lineares e Ensembles: Versatilidade na Modelagem

Os modelos de Machine Learning (ML) usados neste projeto, nomeadamente **K-Nearest Neighbors (KNN)** e os m√©todos de **Ensemble** (**Random Forest** e **XGBoost**), s√£o not√°veis por sua **versatilidade**.

Eles s√£o chamados de "modelos de prop√≥sito geral" porque suas estruturas podem ser adaptadas para resolver problemas de **Regress√£o** (previs√£o de um valor cont√≠nuo) e **Classifica√ß√£o** (previs√£o de uma categoria discreta) sem a necessidade de assumir rela√ß√µes lineares.

### Justificativa da Estrutura de Notebooks

A distin√ß√£o entre as tarefas √© feita na **fun√ß√£o de agrega√ß√£o** final do algoritmo:

| Tipo de Problema | O que o Modelo Previs√≠vel? | Fun√ß√£o Final do Algoritmo | Notebook Correspondente |
| :--- | :--- | :--- | :--- |
| **Regress√£o** | Um **Valor Cont√≠nuo** (Ex: Pre√ßo de Casa) | **M√©dia** das previs√µes das √°rvores ou vizinhos. | `02_Regression_NonLinear_and_Ensembles.ipynb` |
| **Classifica√ß√£o** | Uma **Categoria Discreta** (Ex: Diabetes Sim/N√£o) | **Voto Majorit√°rio** ou **M√©dia das Probabilidades** (usando um limite de corte). | `02_Classification_NonLinear_and_Ensembles.ipynb` |

Esta separa√ß√£o em *notebooks* dedicados garante que as m√©tricas de avalia√ß√£o e as t√©cnicas de otimiza√ß√£o (focadas em **RMSE/R¬≤** para Regress√£o e **AUC-ROC/Acur√°cia** para Classifica√ß√£o) sejam tratadas de forma independente e adequada.

### üöÄ Regress√£o N√£o Linear(KNN) e M√©todos de Ensemble (Random Forest e XGBoost)

#### Comparativo de Desempenho (California Housing)

A tabela abaixo resume os resultados de desempenho em compara√ß√£o com o modelo Linear mais forte (Ridge):

| Modelo | Tipo | Melhor Par√¢metro | R¬≤ (Teste) | RMSE (Teste) | Varia√ß√£o R¬≤ (vs. Ridge) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Ridge (L2)** | Linear | $\lambda=4.3288$ | $0.5959$ | $0.5305$ | Base Linear |
| **KNN** | N√£o Linear | $K=11$ | $0.6869$ | $0.6411$ | $+9.1$ p.p. |
| **Random Forest** | Ensemble | $n_{est}=200, depth=20$ | $0.8060$ | $0.5046$ | $+21.0$ p.p. |
| **XGBoost** | **Ensemble (Boosting)** | $lr=0.1, n_{est}=200, depth=5$ | $\mathbf{0.8358}$ | $\mathbf{0.4642}$ | $\mathbf{+24.0}$ p.p. |

#### Conclus√£o Global: Modelo Preditivo Vencedor

O **XGBoost (Gradient Boosting)** demonstrou ser o modelo mais eficaz:

1.  **Melhor Explica√ß√£o (R¬≤):** Explica $\mathbf{83,58\%}$ da vari√¢ncia no pre√ßo das casas, indicando uma excelente capacidade de modelar as rela√ß√µes complexas do *dataset*.
2.  **Melhor Precis√£o (RMSE):** Obteve o menor erro m√©dio de previs√£o ($\mathbf{0.4642}$), superando todos os outros modelos testados, incluindo o Random Forest.

A estrat√©gia de **Gradient Boosting** ser√° a base para as previs√µes finais do projeto.

---
### üå≥ Classifica√ß√£o N√£o Linear(KNN) e M√©todos de Ensemble (Random Forest e XGBoost)

O **XGBoost (Gradient Boosting)** e o **Random Forest** foram aplicados ao *dataset* Pima Indians Diabetes para explorar o poder dos m√©todos N√£o_Linear e de √°rvore no problema de classifica√ß√£o.

### üåê Classifica√ß√£o com K-Nearest Neighbors (KNN)

O modelo KNN, classificado como N√£o Linear, foi treinado para determinar seu poder preditivo no *dataset* Pima Indians Diabetes.

#### Resultados do KNN Classifier

| M√©trica | Resultado |
| :--- | :--- |
| **Melhor Par√¢metro** | $K=21$ (weights: 'distance') |
| **Acur√°cia (Teste)** | $\mathbf{0.7706}$ |
| **AUC-ROC (Teste)** | $0.8127$ |
| **Recall (Classe 1 - Diabetes)** | $0.54$ |

#### Conclus√£o do KNN

O KNN alcan√ßou a **maior Acur√°cia ($\mathbf{77.06\%}$) de todos os modelos** testados. O modelo se beneficia de um grande n√∫mero de vizinhos ($K=21$), sugerindo que a fronteira de decis√£o √© relativamente suave e que a vota√ß√£o por dist√¢ncia (peso maior para vizinhos mais pr√≥ximos) √© a mais eficaz.

#### Comparativo de Desempenho (Ensemble)

| Modelo | Par√¢metros Otimizados | AUC-ROC (Teste) | Acur√°cia (Teste) | Recall (Classe 1 - Diabetes) |
| :--- | :--- | :--- | :--- | :--- |
| **Random Forest** | $n_{est}=100, depth=5$ | $0.8305$ | $0.7359$ | $0.49$ |
| **XGBoost** | $lr=0.05, n_{est}=100, depth=3$ | $\mathbf{0.8416}$ | $\mathbf{0.7576}$ | $0.54$ |

#### Conclus√£o do Ensemble

O **XGBoost** demonstrou ser o modelo de √°rvore mais poderoso para este problema, superando o Random Forest em todas as m√©tricas gerais de desempenho.

---

### üíâ Modelos Probabil√≠sticos para Classifica√ß√£o (Pima Indians Diabetes)

O *dataset* Pima Indians Diabetes foi utilizado para a classifica√ß√£o bin√°ria (Diabetes: Sim/N√£o), aplicando modelos que estimam probabilidades.

#### Comparativo de Desempenho (Pima Indians Diabetes - Probabil√≠sticos)

| Modelo | Penalidade | M√©trica de Otimiza√ß√£o | AUC-ROC (Teste) | Acur√°cia (Teste) | Recall (Classe 1) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Naive Bayes** | Nenhuma | N/A | $0.8088$ | $0.7446$ | $\mathbf{0.62}$ |
| **Regress√£o Log√≠stica** | L2 ($C=1.0$) | AUC-ROC | $\mathbf{0.8380}$ | $\mathbf{0.7446}$ | $0.52$ |

#### Conclus√£o Parcial

1.  **Regress√£o Log√≠stica** demonstrou ser superior em **capacidade de distin√ß√£o** entre as classes (maior **AUC-ROC: 0.8380**).
2.  O **Naive Bayes** apresentou um **Recall** superior para a classe alvo (Diabetes: $\mathbf{0.62}$), indicando que ele √© mais eficaz em capturar casos positivos reais (menos falsos negativos).

A **Regress√£o Log√≠stica** √© o modelo probabil√≠stico com melhor desempenho geral.

---
### üíâ Modelos de Classifica√ß√£o (Pima Indians Diabetes)

O objetivo desta etapa foi classificar se um paciente ind√≠gena Pima seria diagnosticado com diabetes (Classe 1), utilizando modelos Probabil√≠sticos, N√£o Lineares (KNN) e de Ensemble.

#### Resultados Consolidados

| Modelo | Categoria | Melhor Par√¢metro | AUC-ROC (Teste) | Acur√°cia (Teste) | Recall (Classe 1) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Naive Bayes** | Probabil√≠stico | N/A | $0.8088$ | $0.7446$ | $\mathbf{0.62}$ |
| **Regress√£o Log√≠stica** | Probabil√≠stico | $C=1.0$ | $0.8380$ | $0.7446$ | $0.52$ |
| **KNN** | **N√£o Linear** | $K=21, weights=distance$ | $0.8127$ | $\mathbf{0.7706}$ | $0.54$ |
| **Random Forest** | Ensemble | $n_{est}=100, depth=5$ | $0.8305$ | $0.7359$ | $0.49$ |
| **XGBoost** | **Ensemble (Boosting)** | $lr=0.05, n_{est}=100, depth=3$ | $\mathbf{0.8416}$ | $0.7576$ | $0.54$ |

#### Conclus√£o Geral da Classifica√ß√£o

Os modelos de classifica√ß√£o apresentam um *trade-off* claro:

1.  **Melhor Capacidade de Distin√ß√£o (AUC-ROC):** O **XGBoost** √© o vencedor ($\mathbf{0.8416}$), sendo o mais eficaz em ranquear corretamente as probabilidades de diabetes.
2.  **Melhor Precis√£o Geral (Acur√°cia):** O **KNN** alcan√ßa a maior acur√°cia ($\mathbf{0.7706}$), sendo o modelo que mais frequentemente acerta a previs√£o final.
3.  **Melhor Identifica√ß√£o de Positivos (Recall):** O **Naive Bayes** √© o mais adequado se a prioridade for **minimizar Falsos Negativos** (Recall: $\mathbf{0.62}$).

O **XGBoost** √© o modelo de melhor performance geral (AUC-ROC), mas o **KNN** oferece a maior taxa de acerto.

---
### üìè Modelo de Margem: Support Vector Machine (SVM)

O **SVM** (SVC) busca o hiperplano que maximiza a margem entre as classes. A otimiza√ß√£o selecionou um kernel linear com alta penalidade de erro, similar aos modelos lineares tradicionais.

#### Resultados do SVM Classifier

| M√©trica | Resultado |
| :--- | :--- |
| **Melhor Par√¢metro** | $C=10.0$, **kernel**: **`linear`** |
| **Acur√°cia (Teste)** | $0.7359$ |
| **AUC-ROC (Teste)** | $0.8346$ |
| **Recall (Classe 1 - Diabetes)** | $0.49$ |

#### Conclus√£o do SVM

O SVM, com seu kernel linear, demonstrou um desempenho de distin√ß√£o (**AUC-ROC: 0.8346**) muito pr√≥ximo ao da Regress√£o Log√≠stica, mas com um baixo Recall, indicando que a separa√ß√£o linear √© eficaz, por√©m limitada na identifica√ß√£o dos casos positivos mais dif√≠ceis.

---

### üå≤ √Årvore de Decis√£o (Decision Tree Classifier)

A √Årvore de Decis√£o, como modelo fundamental para os m√©todos de Ensemble, foi otimizada para identificar a profundidade ideal no problema de classifica√ß√£o.

#### Resultados da √Årvore de Decis√£o

| M√©trica | Resultado |
| :--- | :--- |
| **Melhor Par√¢metro** | $max\_depth=5, min\_samples\_split=10$ |
| **Acur√°cia (Teste)** | $0.7619$ |
| **AUC-ROC (Teste)** | $0.8149$ |
| **Recall (Classe 1 - Diabetes)** | $0.44$ |

#### Conclus√£o da √Årvore

Embora a acur√°cia seja alta ($\approx 76.2\%$), o baixo Recall da Classe 1 ($0.44$) indica que o modelo de √°rvore pura tem dificuldade em generalizar os casos positivos de forma isolada, justificando a necessidade dos m√©todos de Ensemble (Random Forest e XGBoost) para melhorar a estabilidade e a performance.

---

### üíâ Modelos de Classifica√ß√£o (Pima Indians Diabetes)

A an√°lise comparativa final no *dataset* Pima Indians Diabetes incluiu 7 modelos de diferentes categorias para a classifica√ß√£o bin√°ria de diabetes.

#### Resultados Consolidados Finais

| Modelo | Categoria | Melhor Par√¢metro | AUC-ROC (Teste) | Acur√°cia (Teste) | Recall (Classe 1) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Naive Bayes** | Probabil√≠stico | N/A | $0.8088$ | $0.7446$ | $\mathbf{0.62}$ |
| **Regress√£o Log√≠stica** | Probabil√≠stico | $C=1.0$ | $0.8380$ | $0.7446$ | $0.52$ |
| **Decision Tree** | **√Årvore** | $max\_depth=5, min\_samples\_split=10$ | $0.8149$ | $0.7619$ | $0.44$ |
| **KNN** | N√£o Linear | $K=21, weights=distance$ | $0.8127$ | $\mathbf{0.7706}$ | $0.54$ |
| **SVM (SVC)** | Margem/Dist√¢ncia | $C=10.0, kernel=linear$ | $0.8346$ | $0.7359$ | $0.49$ |
| **Random Forest** | Ensemble | $n_{est}=100, depth=5$ | $0.8305$ | $0.7359$ | $0.49$ |
| **XGBoost** | Ensemble (Boosting) | $lr=0.05, n_{est}=100, depth=3$ | $\mathbf{0.8416}$ | $0.7576$ | $0.54$ |

#### Conclus√£o Geral da Classifica√ß√£o (Final)

O modelo de melhor desempenho √© o **XGBoost**, que alcan√ßou o maior **AUC-ROC ($\mathbf{0.8416}$)**, indicando a melhor capacidade de ranqueamento e distin√ß√£o entre as classes.

* **Para Distin√ß√£o e Performance Geral (AUC-ROC):** O **XGBoost** √© o vencedor.
* **Para Melhor Precis√£o Geral (Acur√°cia):** O **KNN** possui a maior taxa de acerto ($\mathbf{0.7706}$).
* **Para Minimizar Falsos Negativos (Recall):** O **Naive Bayes** √© o modelo mais sens√≠vel aos casos positivos de diabetes ($\mathbf{0.62}$).
---
### üèÜ Stacking Ensemble (Otimiza√ß√£o Final do AUC-ROC)

A etapa final do projeto de classifica√ß√£o foi a implementa√ß√£o do **Stacking Ensemble** (Generaliza√ß√£o Empilhada) para tentar superar o melhor AUC-ROC individual obtido pelo XGBoost. Esta t√©cnica profissional combina as previs√µes de modelos heterog√™neos, utilizando um **Meta-Modelo** (Regress√£o Log√≠stica) para aprender a ponderar as for√ßas e fraquezas de cada modelo base.

#### Modelos Base (Base Learners)

O Ensemble foi constru√≠do utilizando os quatro modelos mais perform√°ticos de diferentes fam√≠lias:

* **XGBoost:** Melhor ranqueamento (AUC-ROC).
* **Regress√£o Log√≠stica:** Bom ranqueamento e modelo linear.
* **KNN:** Melhor acur√°cia (Modelo n√£o linear baseado em dist√¢ncia).
* **Naive Bayes:** Melhor recall (Modelo probabil√≠stico).

#### Metodologia Stacking

1.  Os modelos de base foram carregados e configurados para produzir **probabilidades** (*predict\_proba*).
2.  O **`StackingClassifier`** foi treinado, utilizando 5-fold cross-validation (`cv=5`) para gerar o novo conjunto de dados de previs√µes.
3.  O **Meta-Modelo** (`LogisticRegression`) foi ajustado neste novo conjunto de previs√µes.

#### Resultado Final do Stacking Ensemble

O Stacking Ensemble demonstrou uma melhoria no AUC-ROC, estabelecendo um novo patamar de desempenho para o projeto:

| Modelo | M√©trica Otimizada | AUC-ROC (Teste) | Acur√°cia (Teste) | Recall (Classe 1) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **XGBoost** (Melhor Individual) | AUC-ROC | $0.8416$ | $0.7576$ | $0.54$ |
| **Stacking Ensemble** | AUC-ROC | $\mathbf{0.8421}$ | $0.74$ | $0.52$ |

**Conclus√£o Final do Projeto:**

O **Stacking Ensemble** √© o **modelo final** recomendado para o problema de classifica√ß√£o bin√°ria no dataset Pima Indians Diabetes, pois alcan√ßou o maior poder de distin√ß√£o entre as classes ($\mathbf{0.8421}$). Embora o ganho tenha sido marginal, ele confirma a robustez do Ensemble.

| Objetivo de Neg√≥cio | Modelo Recomendado | M√©trica |
| :--- | :--- | :--- |
| **M√°xima Triagem/Ranqueamento de Risco** | **Stacking Ensemble** | **AUC-ROC** |
| **M√°xima Detec√ß√£o de Positivos (Sensibilidade)** | **Naive Bayes** | **Recall** ($\mathbf{0.62}$) |