{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb7bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas e prontas para Classificação Pima Indians Diabetes.\n"
     ]
    }
   ],
   "source": [
    "# --- CÉLULA 1: Setup e Carregamento de Bibliotecas (Revisada) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib \n",
    "import os \n",
    "from math import sqrt \n",
    "\n",
    "# Bibliotecas de Pré-processamento e Métricas\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Modelos para Classificação\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "print(\"Bibliotecas importadas e prontas para Classificação Pima Indians Diabetes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b408b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Pima Indians Diabetes carregado com sucesso.\n",
      "Dados Pima Indians Diabetes padronizados e salvos em: data/\n",
      "Shape do X_train: (537, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- CÉLULA 2: Carregamento e Pré-processamento (Pima Indians Diabetes) ---\n",
    "\n",
    "# URL para o dataset (sem cabeçalho)\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\"\n",
    "\n",
    "# Nomes das colunas conforme a documentação\n",
    "col_names = [\n",
    "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'\n",
    "]\n",
    "\n",
    "# 1. Carregamento\n",
    "try:\n",
    "    pima_df = pd.read_csv(url, names=col_names)\n",
    "    print(\"Dataset Pima Indians Diabetes carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar dataset. Verifique a URL ou a conexão: {e}\")\n",
    "\n",
    "# 2. Definição de X e Y\n",
    "X = pima_df.drop('Outcome', axis=1) # Todas as features exceto o alvo\n",
    "y = pima_df['Outcome']               # Alvo: 0 (Não Diabetes), 1 (Diabetes)\n",
    "\n",
    "# 3. Split\n",
    "# Usamos stratify=y para garantir que a proporção das classes seja mantida no treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Padronização (Crucial para Modelos Probabilísticos e Logísticos)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. Salvamento dos Dados (Reutilizando a estrutura de diretórios)\n",
    "DATA_DIR = 'data'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR) \n",
    "\n",
    "joblib.dump(X_train_scaled, os.path.join(DATA_DIR, 'X_train_pima_scaled.joblib'))\n",
    "joblib.dump(X_test_scaled, os.path.join(DATA_DIR, 'X_test_pima_scaled.joblib'))\n",
    "joblib.dump(y_train, os.path.join(DATA_DIR, 'y_train_pima.joblib'))\n",
    "joblib.dump(y_test, os.path.join(DATA_DIR, 'y_test_pima.joblib'))\n",
    "\n",
    "print(f\"Dados Pima Indians Diabetes padronizados e salvos em: {DATA_DIR}/\")\n",
    "print(f\"Shape do X_train: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7419d714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Naive Bayes treinado e salvo em: models\\naive_bayes_classifier_model.joblib\n",
      "\n",
      "Naive Bayes: Acurácia (Teste): 0.7446\n",
      "Naive Bayes: AUC-ROC (Teste): 0.8088\n",
      "\n",
      "Relatório de Classificação (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       150\n",
      "           1       0.64      0.62      0.63        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CÉLULA 3: Naive Bayes (GaussianNB) ---\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. Instanciar e Treinar\n",
    "nb_model = GaussianNB()\n",
    "# Usamos os dados padronizados (scaled), embora o Naive Bayes não seja sensível à escala, é boa prática.\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 2. Salvar o modelo\n",
    "MODEL_DIR = 'models'\n",
    "MODEL_FILENAME = 'naive_bayes_classifier_model.joblib'\n",
    "MODEL_PATH_NB = os.path.join(MODEL_DIR, MODEL_FILENAME)\n",
    "\n",
    "if not os.path.exists(MODEL_DIR): # Já foi criado na Célula 3 do notebook anterior, mas é bom garantir\n",
    "    os.makedirs(MODEL_DIR) \n",
    "\n",
    "joblib.dump(nb_model, MODEL_PATH_NB) \n",
    "print(f\"Modelo Naive Bayes treinado e salvo em: {MODEL_PATH_NB}\")\n",
    "\n",
    "# 3. Avaliação do Modelo\n",
    "\n",
    "# Previsão da classe (0 ou 1)\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "# Previsão da probabilidade da CLASSE 1 (necessário para a métrica AUC-ROC)\n",
    "y_pred_proba_nb = nb_model.predict_proba(X_test_scaled)[:, 1] \n",
    "\n",
    "# Métricas de avaliação\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_proba_nb)\n",
    "\n",
    "print(f\"\\nNaive Bayes: Acurácia (Teste): {accuracy_nb:.4f}\")\n",
    "print(f\"Naive Bayes: AUC-ROC (Teste): {roc_auc_nb:.4f}\")\n",
    "print(\"\\nRelatório de Classificação (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2a79f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Regressão Logística treinado e salvo em: models\\logistic_regression_classifier_model.joblib\n",
      "\n",
      "Regressão Logística: Melhor C encontrado: 1.0\n",
      "Regressão Logística: Acurácia (Teste): 0.7446\n",
      "Regressão Logística: AUC-ROC (Teste): 0.8380\n",
      "\n",
      "Relatório de Classificação (Regressão Logística):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       150\n",
      "           1       0.68      0.52      0.59        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.69      0.70       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CÉLULA 4: Regressão Logística ---\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Definir o range do hiperparâmetro C (Inverso da força de regularização)\n",
    "# Usaremos uma pequena gama de valores para C (regularização L2 padrão)\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1.0, 10.0]} \n",
    "\n",
    "# 2. Configurar o GridSearchCV\n",
    "# O solver 'liblinear' é robusto para small-to-medium datasets e lida bem com L1/L2\n",
    "lr = LogisticRegression(solver='liblinear', random_state=42)\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=param_grid_lr,\n",
    "    scoring='roc_auc', # Focamos na área sob a curva (AUC-ROC) como métrica de otimização\n",
    "    cv=5, \n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. Treinar\n",
    "# A Regressão Logística é sensível à escala, por isso usamos os dados scaled\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Salvar o melhor estimador\n",
    "best_lr_model = lr_grid.best_estimator_\n",
    "\n",
    "MODEL_DIR = 'models'\n",
    "MODEL_FILENAME = 'logistic_regression_classifier_model.joblib'\n",
    "MODEL_PATH_LR = os.path.join(MODEL_DIR, MODEL_FILENAME)\n",
    "\n",
    "joblib.dump(best_lr_model, MODEL_PATH_LR) \n",
    "print(f\"Modelo Regressão Logística treinado e salvo em: {MODEL_PATH_LR}\")\n",
    "\n",
    "# 5. Avaliação do Modelo Otimizado\n",
    "y_pred_lr = best_lr_model.predict(X_test_scaled)\n",
    "# Previsão da probabilidade da CLASSE 1 (coluna de índice 1)\n",
    "y_pred_proba_lr = best_lr_model.predict_proba(X_test_scaled)[:, 1] \n",
    "\n",
    "# Métricas de avaliação\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "best_c = lr_grid.best_params_['C']\n",
    "\n",
    "print(f\"\\nRegressão Logística: Melhor C encontrado: {best_c}\")\n",
    "print(f\"Regressão Logística: Acurácia (Teste): {accuracy_lr:.4f}\")\n",
    "print(f\"Regressão Logística: AUC-ROC (Teste): {roc_auc_lr:.4f}\")\n",
    "print(\"\\nRelatório de Classificação (Regressão Logística):\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_modelos_predicao_estatistica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
